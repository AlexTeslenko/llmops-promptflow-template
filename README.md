# LLMOps with Prompt Flow 
The rise of AI and large language models (LLMs) has transformed various industries, enabling the development of innovative applications with human-like text understanding and generation capabilities. This revolution has opened up new possibilities across fields such as customer service, content creation, and data analysis.

As LLMs rapidly evolve, the importance of Prompt Engineering becomes increasingly evident. Prompt Engineering plays a crucial role in harnessing the full potential of LLMs by creating effective prompts that cater to specific business scenarios. This process enables developers to create tailored AI solutions, making AI more accessible and useful to a broader audience.

# Context
- LLM-infused application are designed to understand and generate human-like text based on the input they receive. They comprise of prompts that needs engineering cadence and rigour.
- Prompt flow is a powerful feature that simplifies and streamlines the Prompt Engineering process for LLM-infused applications. It enables users to create, evaluate, and deploy high-quality flows with ease and efficiency. 
- How do we best augment LLM-infused application with LLMOps and engineering rigour? This template aims to assist in the development of those types of applications using Prompt Flow and LLMOps.

# Proposed Solution

That's where **LLMOps with Prompt Flow** comes in. LLMOps with Prompt Flow is a "LLMOps template and guidance" to help you build LLM-infused apps using Prompt Flow. It provides the following features:

- Offers BYOF (bring-your-own-flows). A **complete platform** for developing multiple use-cases related to LLM-infused applications.
- Offers **configuration** based development. No need to write extensive boiler-plate code.
- Provides execution of both **prompt experimentation and evaluation** locally as well on cloud.
- ability to execute complex flows consisting of multiple **LLM based tools and variants**.
- Provides **notebooks for local evaluation** of the prompts. Provides library of functions for local experimentation.
- Allows use of multiple data assets with each flow for prompt experimentation and evaluation.
- Allows execution of multiple evaluation flows for each prompt experimentation flow.
- Generates evaluation reports in csv as well as html files.
- Deploys the flow to Azure ML endpoint.
- Tests the availability and readiness of the deployment.
- Ability to perform A/B or blue/green deployments.
- Provides optional Human-in-loop to validate prompt metrics before deployment.

LLMOps with Prompt Flow provides capabilities for both simple as well as complex LLM-infused apps. It is completely customizable to the needs of the application.

# Documentation

Full documentation can be found [here](./docs/how_to_setup.md)

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.

## Code of Conduct

This project has adopted the
[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the
[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)
with any additional questions or comments.

## License

Copyright (c) Microsoft Corporation. All rights reserved.

Licensed under the [MIT](LICENSE) license.